{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Face Mask Detection\n",
    "## 1. Introduction\n",
    "**Context**\n",
    "This dataset is used for Face Mask Detection Classification with images. The dataset consists of almost 12K images which are almost 328.92MB in size.\n",
    "\n",
    "**Acknowledgments**\n",
    "All the images with the face mask (~6K) are scrapped from google search and all the images without the face mask are preprocessed from the CelebFace dataset created by Jessica Li (https://www.kaggle.com/jessicali9530). Thank you so much Jessica for providing a wonderful dataset to the community.\n",
    "\n",
    "**Inspiration**\n",
    "The inspiration behind creating this dataset is to create an algorithm that can directly detect is a person is wearing a face mask or not. So I've scrapped the images from google as well as from the CelebFace dataset created by Jessica Li (https://www.kaggle.com/jessicali9530) to make this happen.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The dataset is donwloaded from kaggle [Face Mask Detection ~12K Images Dataset](https://www.kaggle.com/datasets/ashishjangra27/face-mask-12k-images-dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2. Planning\n",
    "1. Data Augmentation to increase dataset size\n",
    "2. Develop and train CNN model to detect face\n",
    "3. Label faces\n",
    "    1. Using Haarcascade find and crop faces\n",
    "    2. using CNN model to predict the result\n",
    "    3. label the faces with predicted result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "from libs.nn.conv import CnnModel\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "import opendatasets as od\n",
    "import numpy as np\n",
    "from imutils import paths\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dowload the dataset\n",
    "dataset_url = 'https://www.kaggle.com/datasets/ashishjangra27/face-mask-12k-images-dataset'\n",
    "\n",
    "# Look into the data directory\n",
    "images_dir = './face-mask-12k-images-dataset/Face Mask Dataset'\n",
    "\n",
    "images_dir_path = pathlib.Path(images_dir)\n",
    "if not os.path.isdir(images_dir):\n",
    "    od.download(dataset_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show random images\n",
    "train_dir = f'{images_dir}/Train'\n",
    "test_dir = f'{images_dir}/Test'\n",
    "valid_dir = f'{images_dir}/Validation'\n",
    "\n",
    "train_imgs = list(paths.list_images(train_dir))\n",
    "test_imgs = list(paths.list_images(test_dir))\n",
    "valid_imgs = list(paths.list_images(valid_dir))\n",
    "\n",
    "len(train_imgs) + len(test_imgs) + len(valid_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_num_array = np.random.randint(len(train_imgs), size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=4, ncols=4, figsize=(12, 8))\n",
    "\n",
    "for ax, num in zip(axs.ravel(), random_num_array):\n",
    "    _img = img.imread(train_imgs[num])\n",
    "    ax.set_title(f'{_img.shape}')\n",
    "    ax.imshow(_img , interpolation='none')\n",
    "    ax.axis(\"off\")\n",
    "# plt.subplots_adjust(wspace=0, hspace=0, left=0, right=1, bottom=0, top=1)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "* we have have total 11792 different kind of colored images with different sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_with_mask = len(list(paths.list_images(f'{images_dir}/Train/WithMask')))\n",
    "total_without_mask = len(list(paths.list_images(f'{images_dir}/Train/WithoutMask')))\n",
    "total_with_mask,total_without_mask"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 4. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_HEIGHT = 64\n",
    "IMG_WIDTH = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_set = keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    class_names=[\"WithMask\", \"WithoutMask\"],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "test_data_set = keras.utils.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    class_names=[\"WithMask\", \"WithoutMask\"],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    seed=42\n",
    ")\n",
    "valid_data_set = keras.utils.image_dataset_from_directory(\n",
    "    valid_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    class_names=[\"WithMask\", \"WithoutMask\"],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = CnnModel.build(width=IMG_WIDTH, height=IMG_HEIGHT, depth=3, classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = SGD(learning_rate=0.005)\n",
    "cnn_model.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_data_set.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = valid_data_set.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                     restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = cnn_model.fit(train_ds, validation_data=val_ds,\n",
    "\tbatch_size=32, epochs=100, verbose=1,callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot( history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot( history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot( history.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot( history.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in test_data_set:\n",
    "    redict = cnn_model.predict(x)\n",
    "    print(redict.argmax(axis=1))\n",
    "    # print (y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.array([])\n",
    "testY =  np.array([])\n",
    "for x, y in test_data_set:\n",
    "    predict = cnn_model.predict(x)\n",
    "    print(max(predict.argmax(axis=1)))\n",
    "    preds = np.concatenate([preds, predict.argmax(axis=1)])\n",
    "    testY = np.concatenate([testY, y])\n",
    "\n",
    "tf.math.confusion_matrix(labels=testY, predictions=preds).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(testY,\n",
    "\ttest_preds.argmax(axis=1),\n",
    "\ttarget_names=[\"WithMask\", \"WithoutMask\"]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Testing on new (real world) images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Future Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Reference"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlcv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "47e993c8dedd233275941fef146d86ebedcc305e79d6dfa19977f8a6ba612235"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
