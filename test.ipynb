{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "from libs.nn.conv import CnnModel\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.image as img\n",
    "import opendatasets as od\n",
    "import numpy as np\n",
    "from imutils import paths\n",
    "import os\n",
    "from libs.preprocessing import ImageToArrayPreprocessor\n",
    "from libs.preprocessing import SimplePreprocessor\n",
    "from libs.datasets import SimpleDatasetLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "dataset_url = 'https://www.kaggle.com/datasets/ashishjangra27/face-mask-12k-images-dataset'\n",
    "\n",
    "# Look into the data directory\n",
    "images_dir = './face-mask-12k-images-dataset/Face Mask Dataset'\n",
    "\n",
    "images_dir_path = pathlib.Path(images_dir)\n",
    "if not os.path.isdir(images_dir):\n",
    "    od.download(dataset_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11792"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = f'{images_dir}/Train'\n",
    "test_dir = f'{images_dir}/Test'\n",
    "valid_dir = f'{images_dir}/Validation'\n",
    "\n",
    "train_imgs = list(paths.list_images(train_dir))\n",
    "test_imgs = list(paths.list_images(test_dir))\n",
    "valid_imgs = list(paths.list_images(valid_dir))\n",
    "\n",
    "len(train_imgs) + len(test_imgs) + len(valid_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_paths = list(paths.list_images(train_dir))\n",
    "valid_img_paths = list(paths.list_images(valid_dir))\n",
    "test_img_paths = list(paths.list_images(test_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_WIDTH = IMG_HEIGHT = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processed 500/10000\n",
      "[INFO] processed 1000/10000\n",
      "[INFO] processed 1500/10000\n",
      "[INFO] processed 2000/10000\n",
      "[INFO] processed 2500/10000\n",
      "[INFO] processed 3000/10000\n",
      "[INFO] processed 3500/10000\n",
      "[INFO] processed 4000/10000\n",
      "[INFO] processed 4500/10000\n",
      "[INFO] processed 5000/10000\n",
      "[INFO] processed 5500/10000\n",
      "[INFO] processed 6000/10000\n",
      "[INFO] processed 6500/10000\n",
      "[INFO] processed 7000/10000\n",
      "[INFO] processed 7500/10000\n",
      "[INFO] processed 8000/10000\n",
      "[INFO] processed 8500/10000\n",
      "[INFO] processed 9000/10000\n",
      "[INFO] processed 9500/10000\n",
      "[INFO] processed 10000/10000\n",
      "[INFO] processed 500/800\n",
      "[INFO] processed 500/992\n"
     ]
    }
   ],
   "source": [
    "# initialize the image preprocessor\n",
    "sp = SimplePreprocessor(IMG_WIDTH, IMG_HEIGHT)\n",
    "iap = ImageToArrayPreprocessor()\n",
    "\n",
    "# load the dataset from disk then scale the raw pixel intensities\n",
    "# to the range [0,1]\n",
    "sdl = SimpleDatasetLoader(preprocessor=[sp, iap])\n",
    "trainX, trainY = sdl.load(train_img_paths, verbose=500)\n",
    "trainX = trainX.astype(\"float\") / 255.0\n",
    "\n",
    "validX, validY = sdl.load(valid_img_paths, verbose=500)\n",
    "validX = validX.astype(\"float\") / 255.0\n",
    "\n",
    "testX, testY = sdl.load(test_img_paths, verbose=500)\n",
    "testX = testX.astype(\"float\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "trainX, trainY = shuffle(trainX, trainY, random_state=42)\n",
    "validX, validY = shuffle(validX, validY, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the labels from integers to vectors\n",
    "label_bin =  LabelBinarizer()\n",
    "trainY =label_bin.fit_transform(trainY)\n",
    "validY =label_bin.transform(validY)\n",
    "testY =label_bin.transform(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "313/313 [==============================] - 4s 6ms/step - loss: 0.6890 - accuracy: 0.7162 - val_loss: 0.6860 - val_accuracy: 0.7175\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.6811 - accuracy: 0.8043 - val_loss: 0.6767 - val_accuracy: 0.8100\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.6682 - accuracy: 0.8464 - val_loss: 0.6605 - val_accuracy: 0.8275\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.6430 - accuracy: 0.8528 - val_loss: 0.6255 - val_accuracy: 0.8525\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.5827 - accuracy: 0.8796 - val_loss: 0.5372 - val_accuracy: 0.8650\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.4517 - accuracy: 0.8798 - val_loss: 0.3907 - val_accuracy: 0.8650\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3259 - accuracy: 0.8895 - val_loss: 0.3114 - val_accuracy: 0.8900\n",
      "Epoch 8/20\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.2771 - accuracy: 0.9001 - val_loss: 0.2889 - val_accuracy: 0.8913\n",
      "Epoch 9/20\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.2577 - accuracy: 0.9060 - val_loss: 0.2695 - val_accuracy: 0.9038\n",
      "Epoch 10/20\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.2465 - accuracy: 0.9075 - val_loss: 0.2659 - val_accuracy: 0.9038\n",
      "Epoch 11/20\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.2384 - accuracy: 0.9127 - val_loss: 0.2560 - val_accuracy: 0.9075\n",
      "Epoch 12/20\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.2319 - accuracy: 0.9149 - val_loss: 0.2486 - val_accuracy: 0.9087\n",
      "Epoch 13/20\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.2251 - accuracy: 0.9198 - val_loss: 0.2399 - val_accuracy: 0.9112\n",
      "Epoch 14/20\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.2187 - accuracy: 0.9210 - val_loss: 0.2336 - val_accuracy: 0.9125\n",
      "Epoch 15/20\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.2139 - accuracy: 0.9212 - val_loss: 0.2267 - val_accuracy: 0.9162\n",
      "Epoch 16/20\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.2079 - accuracy: 0.9231 - val_loss: 0.2240 - val_accuracy: 0.9125\n",
      "Epoch 17/20\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.2038 - accuracy: 0.9257 - val_loss: 0.2184 - val_accuracy: 0.9212\n",
      "Epoch 18/20\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.1987 - accuracy: 0.9264 - val_loss: 0.2191 - val_accuracy: 0.9112\n",
      "Epoch 19/20\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.1941 - accuracy: 0.9277 - val_loss: 0.2161 - val_accuracy: 0.9162\n",
      "Epoch 20/20\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.1887 - accuracy: 0.9292 - val_loss: 0.2017 - val_accuracy: 0.9250\n"
     ]
    }
   ],
   "source": [
    "opt = SGD(learning_rate=1e-3)\n",
    "model = CnnModel.build(width=IMG_WIDTH, height=IMG_HEIGHT, depth=3, classes=1)\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=opt,\n",
    "              metrics=[\"accuracy\"]\n",
    "              )\n",
    "\n",
    "H = model.fit(trainX,\n",
    "              trainY,\n",
    "              validation_data=(validX, validY),\n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=20,\n",
    "              verbose=1\n",
    "              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    WithMask       0.95      0.88      0.91       483\n",
      " WithoutMask       0.89      0.96      0.92       509\n",
      "\n",
      "    accuracy                           0.92       992\n",
      "   macro avg       0.92      0.92      0.92       992\n",
      "weighted avg       0.92      0.92      0.92       992\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(testX, batch_size=BATCH_SIZE)\n",
    "preds[preds >= 0.5] = 1  #.argmax(axis=1)\n",
    "preds[preds < 0.5 ] = 0\n",
    "print(classification_report(testY,\n",
    "                            preds,\n",
    "                            target_names=[\"WithMask\", \"WithoutMask\"])\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(actual, predicted, labels, ds_type):\n",
    "  cm = tf.math.confusion_matrix(actual, predicted)\n",
    "  ax = sns.heatmap(cm, annot=True, fmt='g')\n",
    "  sns.set(rc={'figure.figsize':(8, 8)})\n",
    "  sns.set(font_scale=1.4)\n",
    "  ax.set_title('Confusion matrix of action recognition for ' + ds_type)\n",
    "  ax.set_xlabel('Predicted Action')\n",
    "  ax.set_ylabel('Actual Action')\n",
    "  plt.xticks(rotation=90)\n",
    "  plt.yticks(rotation=0)\n",
    "  ax.xaxis.set_ticklabels(labels)\n",
    "  ax.yaxis.set_ticklabels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(testY.flatten(), preds.flatten(), [\"WithMask\", \"WithoutMask\"], 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlcv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "47e993c8dedd233275941fef146d86ebedcc305e79d6dfa19977f8a6ba612235"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
